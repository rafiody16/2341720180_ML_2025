{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Tugas 1"
      ],
      "metadata": {
        "id": "5FRk0Te8ubL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Import Library"
      ],
      "metadata": {
        "id": "FvF8wCaktZdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1qB0VmQo5SX",
        "outputId": "90da8ad3-38d5-407a-ed71-fd329ca95133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annoy in /usr/local/lib/python3.12/dist-packages (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaAPuB7ro8Y8",
        "outputId": "9088e4b0-7fb2-42b4-e4fa-c586ecaccd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRM0MCRRpHkX",
        "outputId": "aaeec24c-c129-4fc3-935c-3ac894561c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp312-cp312-linux_x86_64.whl size=2528147 sha256=54f540dd17a0d38a23e450c849d2d627cb8240bc67d8dd15728a700695553e8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/39/b3/cbd7f9cbb76501d2d5fbc84956e70d0b94e788aac87bda465e\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import annoy\n",
        "import faiss\n",
        "import hnswlib\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "w0gX4Lz496-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Membuat Dataset"
      ],
      "metadata": {
        "id": "pAzfm1GI99Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs = [\n",
        "    (1000, 2), # 1000 / 2D\n",
        "    (1000, 5), # 1000 / 5D\n",
        "    (1000000, 2), # 1000000 / 2D\n",
        "    (1000000, 5) # 1000000 / 5D\n",
        "]\n",
        "\n",
        "all_datasets = []\n",
        "\n",
        "for i, (n_points, n_dims) in enumerate(configs):\n",
        "  np.random.seed(42 + i)\n",
        "\n",
        "  X = np.float32(np.random.rand(n_points, n_dims) * 100)\n",
        "\n",
        "  query_point = np.float32(np.random.rand(100, n_dims) * 100)\n",
        "\n",
        "  all_datasets.append({\n",
        "      \"data\": X,\n",
        "      \"queries\": query_point,\n",
        "      \"n_points\": n_points,\n",
        "      \"n_dims\": n_dims,\n",
        "      \"info\": f\"{n_points} points, {n_dims}D\"\n",
        "  })"
      ],
      "metadata": {
        "id": "HiDKS-3u-BpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Benchmark"
      ],
      "metadata": {
        "id": "GRWgHExXpl0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "k = 3"
      ],
      "metadata": {
        "id": "jaMW57ViqNSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in all_datasets:\n",
        "  data = dataset[\"data\"]\n",
        "  queries = dataset[\"queries\"]\n",
        "  n_points = dataset[\"n_points\"]\n",
        "  n_dims = dataset[\"n_dims\"]\n",
        "  info = dataset[\"info\"]\n",
        "\n",
        "  num_queries = len(queries)\n",
        "\n",
        "  # ANNOY\n",
        "  time_start = time.time()\n",
        "  annoy_index = annoy.AnnoyIndex(n_dims, 'euclidean')\n",
        "  for i in range(n_points):\n",
        "    annoy_index.add_item(i, data[i])\n",
        "  annoy_index.build(3)\n",
        "  build_time_annoy = time.time() - time_start\n",
        "\n",
        "  time_start = time.time()\n",
        "  for q in queries:\n",
        "    annoy_index.get_nns_by_vector(q, k)\n",
        "  query_time_annoy = (time.time() - time_start) / num_queries * 1000\n",
        "\n",
        "  # FAISS\n",
        "  time_start = time.time()\n",
        "  faiss_index = faiss.IndexFlatL2(n_dims)\n",
        "  faiss_index.add(data)\n",
        "  build_time_faiss = time.time() - time_start\n",
        "\n",
        "  time_start = time.time()\n",
        "  faiss_index.search(queries, k)\n",
        "  query_time_faiss = (time.time() - time_start) / num_queries * 1000\n",
        "\n",
        "  # HNSW\n",
        "  time_start = time.time()\n",
        "  hnsw_index = hnswlib.Index(space='l2', dim=n_dims)\n",
        "  hnsw_index.init_index(max_elements=n_points, ef_construction=200, M=16)\n",
        "  hnsw_index.add_items(data)\n",
        "  build_time_hnsw = time.time() - time_start\n",
        "\n",
        "  time_start = time.time()\n",
        "  hnsw_index.knn_query(queries, k=k)\n",
        "  query_time_hnsw = (time.time() - time_start) / num_queries * 1000\n",
        "\n",
        "  results.append({\n",
        "      \"Config\": info,\n",
        "      \"Metric\": \"Build Time (s)\",\n",
        "      \"ANNOY\": f\"{build_time_annoy:.4f}\",\n",
        "      \"FAISS\": f\"{build_time_faiss:.4f}\",\n",
        "      \"HNSW\": f\"{build_time_hnsw:.4f}\",\n",
        "  })\n",
        "\n",
        "  results.append({\n",
        "      \"Config\": info,\n",
        "      \"Metric\": \"Query Time (ms)\",\n",
        "      \"ANNOY\": f\"{query_time_annoy:.4f}\",\n",
        "      \"FAISS\": f\"{query_time_faiss:.4f}\",\n",
        "      \"HNSW\": f\"{build_time_hnsw:.4f}\",\n",
        "  })\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\n\\n--- Hasil Akhir Benchmark ---\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvyOp1OWpnWM",
        "outputId": "9118402c-4538-4c45-8e2a-682e661f19c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- Hasil Akhir Benchmark ---\n",
            "            Config          Metric   ANNOY  FAISS     HNSW\n",
            "   1000 points, 2D  Build Time (s)  0.0122 0.0001   0.1146\n",
            "   1000 points, 2D Query Time (ms)  0.0072 0.0736   0.1146\n",
            "   1000 points, 5D  Build Time (s)  0.0151 0.0001   0.1240\n",
            "   1000 points, 5D Query Time (ms)  0.0067 0.0655   0.1240\n",
            "1000000 points, 2D  Build Time (s) 10.0013 0.0115 114.1987\n",
            "1000000 points, 2D Query Time (ms)  0.0135 1.6826 114.1987\n",
            "1000000 points, 5D  Build Time (s)  8.3714 0.0258 185.9874\n",
            "1000000 points, 5D Query Time (ms)  0.0129 1.4594 185.9874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil akhir benchmark ke 3 metode yang didapatkan. Metode ANNOY memiliki waktu persiapan (build) paling lambat, namun memiliki waktu pencarian paling cepat."
      ],
      "metadata": {
        "id": "BTjUH1AKtf77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tugas 2"
      ],
      "metadata": {
        "id": "8VJKchNxuXRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Instalasi Library"
      ],
      "metadata": {
        "id": "5GFQmMvSrejo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2qCkQt0ve3l",
        "outputId": "2f601ec2-8a81-4f04-9084-7b5be02a5ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m645.1/647.5 kB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-linux_x86_64.whl size=551809 sha256=38bae4dfcc40696a583992547d43b5e63d7e7a34db012805353adf61be031eee\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ],
      "source": [
        "!pip install annoy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDJ80N-Av-80",
        "outputId": "bb9700a3-4cde-452a-b6fc-6238fe4a3a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyd9lRtNwFIa",
        "outputId": "70e27f5c-608e-4f1b-c47e-b9dfe256ac2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp312-cp312-linux_x86_64.whl size=2528146 sha256=81f26a6c454516efccba59139efcc22f3523e0cca8b4a8cbac519fec49b98433\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/39/b3/cbd7f9cbb76501d2d5fbc84956e70d0b94e788aac87bda465e\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import faiss\n",
        "from annoy import AnnoyIndex\n",
        "import hnswlib\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "rL9AqajoweAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load Datasets"
      ],
      "metadata": {
        "id": "XhEdT00nrkLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('songs_with_attributes_and_lyrics.csv', on_bad_lines='warn', engine='python')\n",
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Standarisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X).astype('float32')\n",
        "\n",
        "k = 10  # jumlah nearest neighbors\n",
        "num_features = X_scaled.shape[1]\n",
        "num_items = X_scaled.shape[0]\n",
        "\n",
        "query_index = 0\n",
        "query_vector = X_scaled[query_index].reshape(1, -1)\n",
        "query_track_name = df.iloc[query_index].get('track_name', f'Track {query_index}')\n",
        "\n",
        "print(f\"Mencari {k} lagu terdekat untuk: '{query_track_name}'\")\n",
        "print(f\"Total data: {num_items} lagu\")\n",
        "\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpgA7CLvwhT1",
        "outputId": "7e87dede-b3ea-406f-cd75-7f9fcae158ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-92211783.py:1: ParserWarning: Skipping line 478120: unexpected end of data\n",
            "\n",
            "  df = pd.read_csv('songs_with_attributes_and_lyrics.csv', on_bad_lines='warn', engine='python')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mencari 10 lagu terdekat untuk: 'Track 0'\n",
            "Total data: 478118 lagu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Exact NN"
      ],
      "metadata": {
        "id": "tvHU_HIfrqJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "nn_exact = NearestNeighbors(n_neighbors=k + 1, algorithm='brute', metric='euclidean')\n",
        "nn_exact.fit(X_scaled)\n",
        "fit_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "distances, indices = nn_exact.kneighbors(query_vector)\n",
        "query_time = time.time() - start_time\n",
        "\n",
        "exact_indices = indices[0][1:]\n",
        "results['Exact NN'] = {'build_time': fit_time, 'query_time': query_time, 'indices': exact_indices}"
      ],
      "metadata": {
        "id": "4sl59RcHzb-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####ANNOY"
      ],
      "metadata": {
        "id": "tIpo3kry0091"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import annoy\n",
        "\n",
        "start_time = time.time()\n",
        "annoy_index = annoy.AnnoyIndex(num_features, 'euclidean')\n",
        "for i in range(num_items):\n",
        "  annoy_index.add_item(i, X_scaled[i])\n",
        "annoy_index.build(10)\n",
        "fit_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "annoy_indices = annoy_index.get_nns_by_vector(query_vector[0], k + 1)\n",
        "query_time = time.time() - start_time\n",
        "\n",
        "annoy_indices = np.array(annoy_indices[1:])\n",
        "results['ANNOY'] = {'build_time': fit_time, 'query_time': query_time, 'indices': annoy_indices}"
      ],
      "metadata": {
        "id": "ssATh1Gq02j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####FAISS"
      ],
      "metadata": {
        "id": "-Db8ThPz2Z3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "faiss_index = faiss.IndexFlatL2(num_features)\n",
        "faiss_index.add(X_scaled)\n",
        "build_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "distances, faiss_indices = faiss_index.search(query_vector, k + 1)\n",
        "query_time = time.time() - start_time\n",
        "\n",
        "faiss_indices = faiss_indices[0][1:]\n",
        "results['FAISS'] = {'build_time': build_time, 'query_time': query_time, 'indices': faiss_indices}"
      ],
      "metadata": {
        "id": "Pwgw4BUr2bQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####HNSW"
      ],
      "metadata": {
        "id": "nyfCNBds3CSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "hnsw_index = hnswlib.Index(space='l2', dim=num_features)\n",
        "hnsw_index.init_index(max_elements=num_items, ef_construction=200, M=16)\n",
        "hnsw_index.add_items(X_scaled, np.arange(num_items))\n",
        "build_time = time.time() - start_time\n",
        "\n",
        "start_time = time.time()\n",
        "hnsw_index.set_ef(50)\n",
        "hnsw_indices, distances = hnsw_index.knn_query(query_vector, k=k + 1)\n",
        "query_time = time.time() - start_time\n",
        "\n",
        "hnsw_indices = hnsw_indices[1:]\n",
        "results['HNSW'] = {'build_time': build_time, 'query_time': query_time, 'indices': hnsw_indices}"
      ],
      "metadata": {
        "id": "4AGRfgRt3DU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hasil Perbandingan"
      ],
      "metadata": {
        "id": "8QNBwS01tkbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"HASIL PERBANDINGAN\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"{'Metode':<15} | {'Waktu Build (s)':<18} | {'Waktu Query (s)':<18} |\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, data in results.items():\n",
        "    build_t = f\"{data['build_time']:.6f}\"\n",
        "    query_t = f\"{data['query_time']:.6f}\"\n",
        "\n",
        "    print(f\"{name:<15} | {build_t:<18} | {query_t:<18} |\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2hXK02p4pRq",
        "outputId": "4dae042e-cd7a-4860-e3fa-ff085ce8d543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "HASIL PERBANDINGAN\n",
            "============================================================\n",
            "Metode          | Waktu Build (s)    | Waktu Query (s)    |\n",
            "------------------------------------------------------------\n",
            "Exact NN        | 0.010652           | 0.021496           |\n",
            "ANNOY           | 9.630796           | 0.000214           |\n",
            "FAISS           | 0.021497           | 0.004399           |\n",
            "HNSW            | 93.667323          | 0.000674           |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan perbandingan antara 4 metode, menunjukkan bahwa meskipun HNSW dan ANNOY adalah metode paling lambat pada saat tahap persiapan (build), keduanya merupakan metode yang paling unggul dalam kecepatan pencarian."
      ],
      "metadata": {
        "id": "AQnc1L_UqOX-"
      }
    }
  ]
}